import streamlit as st
import logging
import re

from ollama import OllamaClient
from agent import KubernetesAgent

# --- Logger Kurulumu ---
# Konsolda daha detaylÄ± bilgi gÃ¶rmek iÃ§in log seviyesini ayarlayabilirsiniz.
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Sayfa YapÄ±landÄ±rmasÄ± ---
st.set_page_config(
    page_title="KUBEX AsistanÄ±",
    page_icon="ğŸ§©",
    layout="wide"
)

if "agent" not in st.session_state:
    st.session_state.agent = None
    st.session_state.connected = False
    st.session_state.messages = []
    st.session_state.pending_action = None


def parse_and_display_response(full_response: str):
    thinking_pattern = re.compile(r"<think>(.*?)</think>", re.DOTALL)
    thinking_content = ""
    main_content = full_response

    match = thinking_pattern.search(full_response)
    if match:
        thinking_content = match.group(1).strip()
        # Ana metinden <think> bloÄŸunu temizle
        main_content = thinking_pattern.sub("", full_response).strip()

    # Sadece iÃ§erik varsa markdown olarak yazdÄ±r
    if main_content:
        st.markdown(main_content)
    # Sadece dÃ¼ÅŸÃ¼nce adÄ±mlarÄ± varsa expander iÃ§inde gÃ¶ster
    if thinking_content:
        with st.expander("Modelin DÃ¼ÅŸÃ¼nce AdÄ±mlarÄ± ğŸ§ "):
            st.markdown(f"```\n{thinking_content}\n```")

# --- ArayÃ¼z ---

# --- Kenar Ã‡ubuÄŸu (Sidebar) ---
with st.sidebar:
    st.header("âš™ï¸ YapÄ±landÄ±rma")
    base_url = st.text_input("Ollama URL", value="http://ai.ikaganacar.com")
    model_name = st.text_input("Model AdÄ±", value="qwen3:4b")

    if st.button("BaÄŸlan", type="primary"):
        with st.spinner("BaÄŸlanÄ±lÄ±yor..."):
            try:
                client = OllamaClient(base_url=base_url, model_name=model_name)
                # BaÄŸlantÄ±yÄ± test et
                if client.test_connection():
                    st.session_state.agent = KubernetesAgent(client)
                    st.session_state.connected = True
                    st.success(f"BaÅŸarÄ±yla baÄŸlanÄ±ldÄ±!\n\n**Model:** {model_name}")
                    st.rerun() # BaÄŸlantÄ± sonrasÄ± arayÃ¼zÃ¼ yenile
                else:
                    st.error("Sunucuya ulaÅŸÄ±ldÄ± ancak API yanÄ±t vermiyor. Ollama'nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun.")
            except Exception as e:
                st.error(f"BaÄŸlanÄ±rken bir hata oluÅŸtu: {e}")
                logger.error(f"BaÄŸlantÄ± hatasÄ±: {e}")

    if st.session_state.connected:
        st.divider()
        if st.button("Sohbeti Temizle"):
            st.session_state.messages = []
            st.session_state.pending_action = None
            # AjanÄ±n iÃ§indeki sohbet geÃ§miÅŸini de temizle
            if st.session_state.agent:
                st.session_state.agent.client.clear_chat_history()
            st.rerun()

# --- Ana Sohbet ArayÃ¼zÃ¼ ---
st.title("KUBEX AsistanÄ±")

# GeÃ§miÅŸ sohbet mesajlarÄ±nÄ± ekrana yazdÄ±r
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Her mesajÄ± <think> etiketlerine karÅŸÄ± kontrol et
        parse_and_display_response(message["content"])

if st.session_state.connected:
    # DURUM 1: Eksik parametreleri toplama formu
    if st.session_state.pending_action:
        pending = st.session_state.pending_action
        with st.form("parameter_form"):
            st.warning("Ä°ÅŸlemi tamamlamak iÃ§in ek bilgilere ihtiyacÄ±m var:")
            collected_params = {}
            for i, param in enumerate(pending["missing_params"]):
                question = pending["questions"][i] if i < len(pending["questions"]) else f"{param} nedir?"
                collected_params[param] = st.text_input(question, key=f"param_{param}_{i}")

            submitted = st.form_submit_button("Bilgileri GÃ¶nder")
            if submitted:
                # Form gÃ¶nderildikten sonra asistan mesaj baloncuÄŸu oluÅŸtur
                with st.chat_message("assistant"):
                    # finalize_request'i Ã§aÄŸÄ±r ve dÃ¶nen canlÄ± akÄ±ÅŸÄ± (generator) yakala
                    response_generator = st.session_state.agent.finalize_request(
                        pending["tool_name"],
                        pending["extracted_params"],
                        collected_params
                    )
                    # st.write_stream ile canlÄ± yanÄ±tÄ± ekrana yazdÄ±r
                    full_response_content = st.write_stream(response_generator)

                # Tamamlanan yanÄ±tÄ± sohbet geÃ§miÅŸine ekle
                st.session_state.messages.append({"role": "assistant", "content": full_response_content})
                # Bekleyen iÅŸlemi temizle ve arayÃ¼zÃ¼ yenile
                st.session_state.pending_action = None
                st.rerun()

    # DURUM 2: Normal sohbet giriÅŸi
    if prompt := st.chat_input("Kubernetes ile ilgili bir soru sorun..."):
        # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ve ekrana ekle
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            response = st.session_state.agent.process_request(prompt)

            if isinstance(response, dict) and response.get("status") == "needs_parameters":
                st.session_state.pending_action = response
                st.rerun() 
            else:
                response_placeholder = st.empty()
                full_response_content = ""
                for chunk in response:
                    full_response_content += chunk
                    with response_placeholder.container():
                        parse_and_display_response(full_response_content)

                # Tamamlanan yanÄ±tÄ± sohbet geÃ§miÅŸine ekle
                st.session_state.messages.append({"role": "assistant", "content": full_response_content})
else:
    st.info("ğŸ‘ˆ LÃ¼tfen Ã¶nce kenar Ã§ubuÄŸundan Ollama sunucusuna baÄŸlanÄ±n.")

